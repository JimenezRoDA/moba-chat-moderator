
import streamlit as st
import pandas as pd
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import classification_report
import json
import time
import random

# --- ConfiguraciÃ³n inicial de la pÃ¡gina de Streamlit ---
# Esta debe ser la PRIMERA llamada a st. en todo el script, despuÃ©s de los imports.
st.set_page_config(
    page_title="Moderador de Chat IA",
    layout="centered",
    page_icon="ğŸ¤–",
    initial_sidebar_state="collapsed" 
)

# --- 0. ConfiguraciÃ³n inicial y carga del modelo/tokenizador ---
FINETUNED_MODEL_PATH = './models/modelo_toxicidad_guardado'
BASE_MODEL_NAME_FOR_TOKENIZER = 'distilbert-base-uncased'

num_classes = 4
id_to_label = {
    0: 'AcciÃ³n/Juego',
    1: 'Gravemente TÃ³xico',
    2: 'Levemente TÃ³xico',
    3: 'No TÃ³xico'
}

label_to_id = {v: k for k, v in id_to_label.items()}

@st.cache_resource
def load_resources_cached(model_path_cached, base_model_name_for_tokenizer_cached, num_labels_cached):
    """
    Carga el tokenizador y el modelo finetuneado, y lo mueve al dispositivo adecuado.
    Esta funciÃ³n se cachea con st.cache_resource para una carga Ãºnica.
    """
    try:
        tokenizer = AutoTokenizer.from_pretrained(base_model_name_for_tokenizer_cached)
        model = AutoModelForSequenceClassification.from_pretrained(model_path_cached, num_labels=num_labels_cached)
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model.to(device)
        model.eval()

        
        return tokenizer, model, device

    except Exception as e:
        st.error(f"Â¡Ups! Error al cargar el modelo o tokenizador desde '{model_path_cached}': {e}")
        st.info("AsegÃºrate de que el modelo estÃ© entrenado y guardado correctamente en esa ruta.")
        st.info("Si estÃ¡s ejecutando la app por primera vez o has movido archivos, verifica la ruta y los permisos.")
        return None, None, None

# Llama a la funciÃ³n cacheada para cargar los recursos
tokenizer, model, device = load_resources_cached(FINETUNED_MODEL_PATH, BASE_MODEL_NAME_FOR_TOKENIZER, num_classes)

if model is None or tokenizer is None:
    st.stop() # Detiene la ejecuciÃ³n de la app si el modelo no se pudo cargar

# --- InicializaciÃ³n de variables de estado de Streamlit ---
# Todas las variables de sesiÃ³n deben inicializarse para evitar errores.
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'grave_count' not in st.session_state:
    st.session_state.grave_count = 0
if 'leve_count' not in st.session_state:
    st.session_state.leve_count = 0
if 'is_banned' not in st.session_state:
    st.session_state.is_banned = False
if 'chat_input' not in st.session_state: # Para el widget de texto del chat
    st.session_state.chat_input = ""

# Umbrales configurables por la empresa para la DemostraciÃ³n Interactiva
if 'max_graves' not in st.session_state:
    st.session_state.max_graves = 3 # Valor por defecto
if 'max_leves' not in st.session_state:
    st.session_state.max_leves = 5 # Valor por defecto
if 'ban_threshold_graves' not in st.session_state:
    st.session_state.ban_threshold_graves = 10 # Umbral de baneo por graves
if 'ban_threshold_total_toxic' not in st.session_state:
    st.session_state.ban_threshold_total_toxic = 15 # Umbral de baneo por toxicidad total

# --- Funciones Auxiliares ---
def get_prediction(text, tokenizer, model, device, id_to_label):
    if model is None or tokenizer is None:
        return "Modelo no cargado", None, None

    inputs = tokenizer(
        text,
        truncation=True,
        padding='max_length',
        max_length=256,
        return_tensors='pt'
    ).to(device)

    with torch.no_grad():
        outputs = model(**inputs)

    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].cpu().numpy()
    predicted_id = np.argmax(probabilities).item()
    predicted_label = id_to_label[predicted_id]

    return predicted_label, probabilities, predicted_id

# FunciÃ³n para resetear la demo (usada en la DemostraciÃ³n Interactiva)
def reset_demo():
    st.session_state.grave_count = 0
    st.session_state.leve_count = 0
    # Aseguramos que tambiÃ©n se resetean los contadores de aliados/enemigos
    st.session_state.grave_count_ally = 0
    st.session_state.leve_count_ally = 0
    st.session_state.grave_count_enemy = 0
    st.session_state.leve_count_enemy = 0
    st.session_state.is_banned = False
    st.session_state.chat_history = []
    st.session_state.chat_input = "" 

# FunciÃ³n para crear burbujas de mensaje HTML
def create_bubble(message, sender="tÃº", msg_type="normal"):
    colors = {
        "grave": "#ffcccc", # Rojo claro
        "leve": "#ffe0b2",  # Naranja claro
        "no_toxic": "#e0f7fa", # Azul muy claro
        "action": "#e8f5e9", # Verde claro
        "system": "#eeeeee", # Gris muy claro
        "enemy": "#f3e5f5",  # Morado claro
        "ally": "#dcedc8",   # Verde pistacho claro
        "warning": "#fff3cd", # Amarillo claro
        "ban": "#f8d7da",    # Rojo muy claro, mÃ¡s pastel
    }
    style = f"background-color:{colors.get(msg_type, '#f0f0f0')};border-radius:10px;padding:10px;margin:6px 0"
    return f"""
    <div style='{style}'>
        <strong>{sender}:</strong> {message}
    </div>
    """

def logo():
    return """
    <div style='
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        text-align: center;
        padding: 20px 0;
        user-select: none;
    '>
        <h1 style='
            font-size: 56px;
            font-weight: 900;
            color: #4a90e2;
            margin: 0;
            letter-spacing: 3px;
            text-shadow: 1px 1px 3px rgba(0,0,0,0.1);
        '>
            <span style='color:#262730;'>Moderador</span> <span style='color:#4a90e2;'>Inteligente</span> <span style='color:#262730;'>de Chat</span>
        </h1>
        <p style='
            margin-top: 6px;
            font-size: 18px;
            color: #666666;
            font-weight: 500;
            letter-spacing: 1px;
        '>
            Tu Aliado en la ModeraciÃ³n Online
        </p>
    </div>
    """

# --- NAVEGACIÃ“N CON PESTAÃ‘AS (TABS) ---
tab_intro, tab_demo, tab_csv, tab_performance, tab_conclusions = st.tabs([
    "1. IntroducciÃ³n",
    "2. DemostraciÃ³n Interactiva",
    "3. Herramienta de AnÃ¡lisis",
    "4. Rendimiento ",
    "5. PrÃ³ximos Pasos"
])

# --- Contenido de las PÃ¡ginas ---

with tab_intro:
    st.markdown(logo(), unsafe_allow_html=True)

    # Imagen decorativa (moderna y sin warnings)
    st.image(
        "https://images.unsplash.com/photo-1519389950473-47ba0277781c?auto=format&fit=crop&w=800&q=80",
        caption="ModeraciÃ³n con IA en comunidades digitales",
        use_container_width=True
    )

    st.markdown("---")

    # SecciÃ³n: Â¿Por quÃ© un Moderador de Chat con IA?
    with st.container():
        st.header("ğŸ¯ Â¿Por quÃ© un Moderador de Chat con IA?")

        st.subheader("ğŸš¨ Un problema creciente")
        st.markdown("""
        La toxicidad en los entornos online, especialmente en videojuegos multijugador, se ha convertido en un problema creciente que afecta tanto a los usuarios como a las plataformas que los albergan.
        """)

        st.subheader("ğŸ“Š Datos alarmantes")
        st.markdown("""
        - MÃ¡s del **80%** de los jugadores han experimentado algÃºn tipo de acoso en juegos en lÃ­nea.  
        - Un **68%** ha recibido amenazas fÃ­sicas, acecho o acoso sostenido.  
        - El **53%** ha sido vÃ­ctima de ataques basados en **raza**, **gÃ©nero**, **orientaciÃ³n sexual** u otros aspectos personales.
        """)

        st.subheader("ğŸ§  Consecuencias reales")
        st.markdown("""
        Este tipo de comportamiento no solo **deteriora la experiencia del usuario**, sino que tambiÃ©n genera consecuencias serias a nivel social:

        - **Aislamiento**  
        - **Ansiedad**  
        - **Pensamientos depresivos**
        """)

        st.subheader("ğŸ¤– Una soluciÃ³n inteligente")
        st.markdown("""
        Un **Moderador de Chat Inteligente** basado en IA no solo detecta y filtra mensajes tÃ³xicos, sino que tambiÃ©n:

        - **Protege** a las comunidades digitales.  
        - **Garantiza** un entorno seguro y saludable para todos.
        """)

    st.markdown("---")

    # SecciÃ³n: Â¿Por quÃ© esto importa a las empresas?
    with st.container():
        st.header("ğŸ¢ Â¿Por quÃ© esto importa a las empresas?")

        st.subheader("ğŸ’¬ La toxicidad va mÃ¡s allÃ¡ de los videojuegos")
        st.markdown("""
        Plataformas con interacciÃ³n constante â€” como **foros**, **redes sociales**, **e-commerce** o **servicios de atenciÃ³n al cliente** â€” tambiÃ©n enfrentan este reto.
        """)

        st.subheader("ğŸ’¼ Ventajas comerciales de usar IA")
        st.markdown("""
        - âœ… **Mejora la experiencia del usuario**: Los entornos saludables incrementan la satisfacciÃ³n, retenciÃ³n y *engagement*.  
        - ğŸ›¡ï¸ **ProtecciÃ³n de la marca**: Evita que contenidos daÃ±inos afecten la reputaciÃ³n empresarial.  
        - âš¡ **Escalabilidad y eficiencia**: Modera grandes volÃºmenes en tiempo real, sin fatiga ni sesgos.  
        - ğŸ’¸ **ReducciÃ³n de costos**: Disminuye la necesidad de equipos humanos para tareas repetitivas.  
        - ğŸ” **AnÃ¡lisis y prevenciÃ³n**: Detecta patrones tÃ³xicos para anticiparse a futuros problemas.
        """)

    st.markdown("---")

    # SecciÃ³n: Fuentes y estudios relevantes
    with st.container():
        st.subheader("ğŸ“š Fuentes y estudios relevantes")
        with st.expander("ğŸ” Consulta las investigaciones que respaldan estos datos"):
            st.markdown("""
            - ğŸ“ˆ *El TelÃ©grafo (2024)* reporta que el acoso en juegos online aumentÃ³ un **74%** en el Ãºltimo aÃ±o. MÃ¡s del **80%** de jugadores han sufrido acoso, y el **68%** recibiÃ³ amenazas fÃ­sicas, acecho o acoso sostenido.  
              [Ver artÃ­culo](https://www.eltelegrafo.com.ec/noticias/sociedad/6/acoso-juegos-online-aumento-ultimo-ano)

            - ğŸ“Š *Pew Research Center (2021)* seÃ±ala que el **41%** de los adultos en EE.UU. ha sido acosado online, un problema transversal en mÃºltiples plataformas.  
              [Ver estudio](https://www.pewresearch.org/internet/2021/01/13/the-state-of-online-harassment/)
            """)

with tab_demo:

    with st.sidebar:
        st.header("âš™ï¸ Ajustes de umbrales")

        # AsegÃºrate de que los sliders usan las variables de st.session_state para sus valores
        st.session_state.max_graves = st.slider(
            "ğŸ”´ Umbral de advertencia grave", 1, 10,
            value=st.session_state.max_graves, key="slider_max_graves" # AÃ±adido key
        )
        st.session_state.max_leves = st.slider(
            "ğŸŸ  Umbral de advertencia leve", 1, 10,
            value=st.session_state.max_leves, key="slider_max_leves" # AÃ±adido key
        )
        st.session_state.ban_threshold_graves = st.slider(
            "ğŸš« Umbral para ban por graves", 1, 10,
            value=st.session_state.ban_threshold_graves, key="slider_ban_graves" # AÃ±adido key
        )
        st.session_state.ban_threshold_total_toxic = st.slider(
            "ğŸš« Umbral para ban por total tÃ³xicos", 1, 20,
            value=st.session_state.ban_threshold_total_toxic, key="slider_ban_total" # AÃ±adido key
        )

        if st.button("Reiniciar Demo", key="reset_demo_button_sidebar"):
            reset_demo()
           

    st.title("ğŸ¤– Demo Interactivo: Moderador de Chat")
    st.markdown("---")

    st.header("ğŸ¤” Â¿CÃ³mo funciona esta demo?")
    st.markdown(f"""
    Esta es una **simulaciÃ³n de chat moderado por IA**. Puedes enviar mensajes y ver cÃ³mo el sistema los clasifica y actÃºa en consecuencia.

    1. âœï¸ **Escribe un mensaje** en la caja de texto inferior.
    2. ğŸ“¤ Haz clic en **"Enviar mensaje"** o presiona `Enter`.
    3. ğŸ¤– El mensaje serÃ¡ clasificado por el modelo en una de las **{num_classes} categorÃ­as**: {', '.join(id_to_label.values())}.
    4. âš ï¸ Si el mensaje se detecta como **tÃ³xico**, aparecerÃ¡ una advertencia y se contarÃ¡ en los indicadores superiores.
    5. ğŸš« Si superas ciertos **umbrales de toxicidad** (configurables en la barra lateral), serÃ¡s **bloqueado** del chat.
    6. ğŸ“Š En los contadores superiores se muestra tanto tu comportamiento como el de los personajes simulados (aliado y enemigo).
    7. ğŸ”„ Usa el botÃ³n **"Reiniciar Demo"** para empezar de nuevo cuando lo necesites.
    """)

    st.info("""
    ğŸ—¨ï¸ Para simular una conversaciÃ³n real, el sistema genera automÃ¡ticamente **mensajes aleatorios** de un **aliado** y un **enemigo** tras cada mensaje tuyo.  
    â— **Importante**: estos mensajes **no responden directamente a tus mensajes**, son generados aleatoriamente. Este sistema no es un bot de conversaciÃ³n, sino una inteligencia artificial que clasifica mensajes de chat segÃºn su tono.
    """)


    st.markdown("---")

    st.subheader("Simulador de chat")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Tus mensajes tÃ³xicos graves", st.session_state.grave_count)
        st.metric("Tus mensajes tÃ³xicos leves", st.session_state.leve_count)
    with col2:
        # Asegurarse de que estas variables estÃ©n inicializadas en reset_demo o al inicio del script
        if 'grave_count_ally' not in st.session_state: st.session_state.grave_count_ally = 0
        if 'leve_count_ally' not in st.session_state: st.session_state.leve_count_ally = 0
        st.metric("Aliado - tÃ³xicos graves", st.session_state.grave_count_ally)
        st.metric("Aliado - tÃ³xicos leves", st.session_state.leve_count_ally)
    with col3:
        # Asegurarse de que estas variables estÃ©n inicializadas en reset_demo o al inicio del script
        if 'grave_count_enemy' not in st.session_state: st.session_state.grave_count_enemy = 0
        if 'leve_count_enemy' not in st.session_state: st.session_state.leve_count_enemy = 0
        st.metric("Enemigo - tÃ³xicos graves", st.session_state.grave_count_enemy)
        st.metric("Enemigo - tÃ³xicos leves", st.session_state.leve_count_enemy)

    # --- LÃ³gica de baneo y chat ---
    # La visualizaciÃ³n del historial de chat se mueve aquÃ­, antes del input,
    # para que siempre sea visible, incluso si el usuario estÃ¡ baneado.
    st.markdown("### Historial del Chat:")
    # Mostrar el chat histÃ³rico (en orden cronolÃ³gico si se prefiere)
    # Si quieres el mÃ¡s nuevo arriba, usa reversed(st.session_state.chat_history)
    for bubble in st.session_state.chat_history:
        st.markdown(bubble, unsafe_allow_html=True)

    if st.session_state.is_banned:
        st.markdown(create_bubble("ğŸš« Â¡HAS SIDO BLOQUEADO DEL CHAT! ğŸš« Excediste los lÃ­mites de toxicidad.", "ğŸ›‘ Sistema", "ban"), unsafe_allow_html=True)
        if st.button("Desbloquear (Reiniciar Demo)", key="unban_button"):
            reset_demo()
            # st.experimental_rerun() # No es necesario aquÃ­

    else:
        # --- FunciÃ³n Callback para el envÃ­o de mensaje ---
        def send_message_and_update_demo():
            user_message = st.session_state.chat_input # Accede al valor del input con su key

            if not user_message: # Si el mensaje estÃ¡ vacÃ­o
                st.warning("Por favor, escribe un mensaje.")
                return # Salir de la funciÃ³n si no hay mensaje

            # Realizar predicciÃ³n: Â¡AquÃ­ es donde se usa el modelo!
            predicted_label, probabilities, predicted_id = get_prediction(user_message, tokenizer, model, device, id_to_label)

            # --- AÃ±adir mensaje del usuario al historial ---
            if predicted_label == id_to_label[1]:  # Gravemente TÃ³xico
                st.session_state.grave_count += 1
                bubble = create_bubble(user_message + f"<br><em>Clasificado como: <b>{predicted_label}</b></em>", "ğŸ§‘ TÃº", "grave")
                st.session_state.chat_history.append(bubble)
                if st.session_state.grave_count >= st.session_state.max_graves:
                    warning = create_bubble("ğŸš¨ ADVERTENCIA: Demasiados mensajes tÃ³xicos graves.", "âš ï¸ Sistema", "warning")
                    st.session_state.chat_history.append(warning)
                if st.session_state.grave_count >= st.session_state.ban_threshold_graves:
                    st.session_state.is_banned = True
                    ban_msg = create_bubble("ğŸš« Has sido bloqueado por toxicidad grave.", "ğŸ›‘ Sistema", "ban")
                    st.session_state.chat_history.append(ban_msg)

            elif predicted_label == id_to_label[2]:  # Levemente TÃ³xico
                st.session_state.leve_count += 1
                bubble = create_bubble(user_message + f"<br><em>Clasificado como: <b>{predicted_label}</b></em>", "ğŸ§‘ TÃº", "leve")
                st.session_state.chat_history.append(bubble)
                if st.session_state.leve_count >= st.session_state.max_leves:
                    warning = create_bubble("âš ï¸ AVISO: Varios mensajes tÃ³xicos leves.", "âš ï¸ Sistema", "warning")
                    st.session_state.chat_history.append(warning)
                if (st.session_state.grave_count + st.session_state.leve_count) >= st.session_state.ban_threshold_total_toxic:
                    st.session_state.is_banned = True
                    ban_msg = create_bubble("ğŸš« Has sido bloqueado por toxicidad acumulada.", "ğŸ›‘ Sistema", "ban")
                    st.session_state.chat_history.append(ban_msg)

            elif predicted_label == id_to_label[3]:  # No TÃ³xico
                bubble = create_bubble(user_message + f"<br><em>Clasificado como: <b>{predicted_label}</b></em>", "ğŸ§‘ TÃº", "no_toxic")
                st.session_state.chat_history.append(bubble)

            else: # AcciÃ³n/Juego
                bubble = create_bubble(user_message + f"<br><em>Clasificado como: <b>{predicted_label}</b></em>", "ğŸ§‘ TÃº", "action")
                st.session_state.chat_history.append(bubble)

            # --- Mensajes aleatorios de Aliado/Enemigo ---
            def ally_message_generator(): # Renombrado para evitar conflicto con la funciÃ³n ally_message() anterior
                options = [
                    # No toxic
                    ("wp", "no_toxic"),
                    ("Gj, team!", "no_toxic"),
                    ("You're doing great!", "no_toxic"),
                    ("gg", "no_toxic"),
    
                    # Action/gameplay
                    ("Push mid!", "action"),
                    ("Group up!", "action"),
                    ("Defend the tower!", "action"),
                    ("Fall back!", "action"),
    
                    # Mild toxicity
                    ("Why are you feeding?", "leve"),
                    ("Do something, please.", "leve"),
                    ("You're making it harder for everyone.", "leve"),
                    ("Wake up, this is ranked!", "leve"),

                    # Severe toxicity
                    ("You're completely useless.", "grave"),
                    ("Uninstall the game.", "grave"),
                    ("STUPID", "grave"),
                    ("We're losing because you DUMB.", "grave")
]
                text, msg_type = random.choice(options)
                if msg_type == "grave":
                    st.session_state.grave_count_ally += 1
                elif msg_type == "leve":
                    st.session_state.leve_count_ally += 1
                return create_bubble(text, "ğŸŸ¢ Aliado", "ally") # Usar "ally" para el tipo de burbuja

            def enemy_message_generator(): # Renombrado
                options = [
                    # No toxic
                    ("You're not bad... for a beginner.", "no_toxic"),
                    ("GG so far.", "no_toxic"),
                    ("You're lucky this time.", "no_toxic"),
                    ("gl hf", "no_toxic"),

                    # Action/gameplay
                    ("I'm pushing top.", "action"),
                    ("Don't let them take it!", "action"),
                    ("We need to end this now.", "action"),
                    ("Farm and group mid.", "action"),

                    # Mild toxicity
                    ("surrender already, boring game", "leve"),
                    ("EZ, learn how to play", "leve"),
                    ("You play like a bot.", "leve"),
                    ("You're the reason your team is losing.", "leve"),

                    # Severe toxicity
                    ("You're absolute garbage.", "grave"),
                    ("Go cry, bitch.", "grave"),
                    ("Did you forget how to play? are you a girl? ", "grave"),
                    ("You're the worst player I've seen, and thats sad", "grave")
]
                text, msg_type = random.choice(options)
                if msg_type == "grave":
                    st.session_state.grave_count_enemy += 1
                elif msg_type == "leve":
                    st.session_state.leve_count_enemy += 1
                return create_bubble(text, "ğŸ”´ Enemigo", "enemy") # Usar "enemy" para el tipo de burbuja

            # AÃ±adir mensajes de IA al historial
            st.session_state.chat_history.append(ally_message_generator())
            st.session_state.chat_history.append(enemy_message_generator())

            # Vaciar el input de texto despuÃ©s de todo el procesamiento
            st.session_state.chat_input = ""
            # No necesitas st.experimental_rerun() aquÃ­, on_click maneja el refresco.


        # El campo de entrada de texto
        # Ya no usamos on_change para limpiar, se limpia dentro del callback
        st.text_input("Escribe tu mensaje aquÃ­:", key="chat_input")

        # El botÃ³n que activa la funciÃ³n callback para enviar y procesar el mensaje
        st.button("Enviar mensaje", on_click=send_message_and_update_demo, key="send_message_button_demo")

    # Mover la visualizaciÃ³n del historial de chat arriba para que siempre sea visible
    # st.markdown("### Historial del Chat:") # Ya lo puse arriba

with tab_csv:
    st.title("ğŸ› ï¸ Herramienta de AnÃ¡lisis de Toxicidad por Lotes")
    st.markdown("---")

    st.header("Carga tu CSV de Comentarios")
    st.write("""
    Esta herramienta te permite subir un archivo CSV con una columna de comentarios
    y el modelo de IA aÃ±adirÃ¡ una nueva columna clasificando cada comentario
    en 'Gravemente TÃ³xico', 'Levemente TÃ³xico', 'No TÃ³xico' o 'AcciÃ³n/Juego'.
    """)

    uploaded_file = st.file_uploader("Sube tu archivo CSV aquÃ­", type="csv")

    if uploaded_file is not None:
        try:
            df_upload = pd.read_csv(uploaded_file)
            st.success("Archivo CSV cargado exitosamente.")
            st.dataframe(df_upload.head())

            # Permite al usuario seleccionar la columna si no es obvio
            column_to_analyze = st.selectbox(
                "Selecciona la columna que contiene los comentarios:",
                df_upload.columns,
                key="csv_column_selector" # AÃ±adido key
            )

            if st.button("Analizar Comentarios", key="analyze_csv_button"): # AÃ±adido key
                if model is not None and tokenizer is not None:
                    with st.spinner("Analizando comentarios... Esto puede tardar unos minutos para archivos grandes."):
                        predictions = []
                        # Asegurarse de que los comentarios son strings y manejar NaN/vacÃ­os
                        for comment in df_upload[column_to_analyze].astype(str).fillna(''):
                            predicted_label, _, _ = get_prediction(comment, tokenizer, model, device, id_to_label)
                            predictions.append(predicted_label)

                        df_upload['clasificacion_toxicidad'] = predictions
                        st.subheader("Resultados del AnÃ¡lisis:")
                        st.dataframe(df_upload)

                        # OpciÃ³n de descarga
                        csv_output = df_upload.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="Descargar CSV con Clasificaciones",
                            data=csv_output,
                            file_name="comentarios_clasificados.csv",
                            mime="text/csv",
                            key="download_classified_csv" # AÃ±adido key
                        )
                else:
                    st.error("El modelo no estÃ¡ cargado. No se puede realizar el anÃ¡lisis.")
        except Exception as e:
            st.error(f"Error al leer o procesar el archivo CSV: {e}")
            st.info("AsegÃºrate de que el archivo es un CSV vÃ¡lido y que no contiene caracteres problemÃ¡ticos.")


with tab_performance:
    st.title("ğŸ“ˆ Rendimiento del Modelo: Fiabilidad y Capacidades")
    st.markdown("---")

    st.header("Â¿Hasta quÃ© punto es fiable nuestro moderador IA?")
    st.write("""
    Nuestro modelo de Inteligencia Artificial es el corazÃ³n de este sistema de moderaciÃ³n. Ha sido entrenado
    con mucho cuidado y probado a fondo para asegurar que es **eficaz y fiable**. AquÃ­ te explicamos, de
    forma sencilla, quÃ© tan bien funciona y dÃ³nde brilla mÃ¡s.
    """)

    # --- DATOS DE RENDIMIENTO HARDCODEADOS DIRECTAMENTE EN EL CÃ“DIGO ---
    # Estos son los datos que antes se cargaban del JSON. Ahora estÃ¡n aquÃ­.
    hardcoded_report_data = {
        "AcciÃ³n/Juego": {"precision": 0.739, "recall": 0.845, "f1-score": 0.788, "support": "N/A"}, # 'support' es el nÃºmero de ejemplos
        "Gravemente TÃ³xico": {"precision": 0.872, "recall": 0.886, "f1-score": 0.879, "support": "N/A"},
        "Levemente TÃ³xico": {"precision": 0.793, "recall": 0.718, "f1-score": 0.753, "support": "N/A"},
        "No TÃ³xico": {"precision": 0.954, "recall": 0.954, "f1-score": 0.954, "support": "N/A"},
        "accuracy": 0.9174,
        "macro avg": {"precision": 0.8395, "recall": 0.85075, "f1-score": 0.8435, "support": "N/A"},
        "weighted avg": {"precision": 0.9175, "recall": 0.9174, "f1-score": 0.9175, "support": "N/A"}
    }

    # Creamos el DataFrame directamente desde los datos hardcodeados
    report_df = pd.DataFrame(hardcoded_report_data).transpose()

    # Redondeamos las columnas numÃ©ricas para una mejor visualizaciÃ³n
    # y manejamos el caso de 'accuracy' que no es un diccionario
    for col in ['precision', 'recall', 'f1-score']:
        if col in report_df.columns:
            report_df[col] = pd.to_numeric(report_df[col], errors='coerce').round(3)
    if 'accuracy' in report_df.index:
        report_df.loc['accuracy'] = pd.to_numeric(report_df.loc['accuracy'], errors='coerce').round(4) # Accuracy puede tener mÃ¡s decimales


    st.subheader("MÃ©tricas de EvaluaciÃ³n Detalladas:")
    st.dataframe(report_df)

    st.markdown("""
    ### **Â¿CÃ³mo se comporta el modelo? Un resumen para todos:**

    Imagina que el modelo es como un **experto revisor de chat**. Analiza los mensajes y decide
    si son tÃ³xicos o no. Basado en nuestras pruebas, aquÃ­ te contamos lo que hace genial y dÃ³nde puede mejorar:

    ---

    #### **âœ… Lo que el modelo hace EXCEPCIONALMENTE bien (Puntos Fuertes):**

    * **Detecta la toxicidad mÃ¡s grave (Â¡Y muy bien!):** Cuando un mensaje es **"Gravemente TÃ³xico"**, nuestro modelo es **muy, muy bueno** identificÃ¡ndolo. Tiene una fiabilidad de casi el **88%** en esta tarea. Esto es crucial porque significa que los mensajes mÃ¡s daÃ±inos y problemÃ¡ticos son rÃ¡pidamente detectados y gestionados. Protege a tu comunidad de lo peor.

    * **Reconoce lo que NO es tÃ³xico (Â¡Casi perfecto!):** El modelo es **excelente** a la hora de decir cuÃ¡ndo un mensaje es **"No TÃ³xico"**. Con una fiabilidad del **95.4%**, casi nunca se equivoca al dejar pasar conversaciones normales y saludables. Esto es vital para no molestar a los usuarios que se comunican bien.

    * **PrecisiÃ³n general impresionante:** En total, el modelo acierta en casi **9 de cada 10 mensajes** (un **91.74%** de precisiÃ³n general). Esto nos dice que, en la mayorÃ­a de los casos, puedes confiar en su criterio para mantener el chat limpio.

    ---

    #### **âš ï¸ DÃ³nde el modelo puede ser mÃ¡s "cauteloso" (Ãreas de Oportunidad):**

    * **Toxicidad leve (el matiz es complicado):** Identificar la toxicidad **"Levemente TÃ³xica"** es el reto mÃ¡s grande. Piensa en el sarcasmo, las indirectas o los comentarios un poco molestos pero no tan agresivos. AquÃ­ el modelo es **razonablemente bueno** (alrededor del **75.3%**), pero a veces puede **dejar pasar** algunos mensajes sutiles. Esto es normal en la IA, ya que la lÃ­nea entre un comentario "regular" y uno "ligeramente tÃ³xico" puede ser muy fina y subjetiva para una mÃ¡quina.

    * **Mensajes de "AcciÃ³n/Juego":** Aunque clasifica bien la mayorÃ­a, en los mensajes de **"AcciÃ³n/Juego"** (como "Â¡Vamos a por el objetivo!"), su precisiÃ³n es un poco mÃ¡s baja (alrededor del **78.8%**). A veces, puede confundir estos mensajes con otros "No TÃ³xicos". Esto se debe a que el lenguaje del juego puede ser muy similar al de las conversaciones normales.

    ---

    #### **En resumen:**

    Este moderador es una **herramienta poderosa y muy fiable** para detectar los mensajes mÃ¡s peligrosos y para asegurar que el chat normal fluye sin problemas. Para las toxicidades mÃ¡s sutiles o las categorÃ­as de contenido especÃ­ficas, es una base excelente que puede mejorarse con el tiempo y el uso.

    ---
    """)

    # --- La secciÃ³n de descarga del PDF se mantiene igual ---
    st.markdown("---")
    st.header("Â¿Quieres ver los nÃºmeros exactos en detalle?")
    st.write("""
    Para aquellos interesados en los detalles tÃ©cnicos, las mÃ©tricas completas y un anÃ¡lisis exhaustivo
    del rendimiento de nuestro modelo, puedes descargar el informe completo de evaluaciÃ³n aquÃ­.
    Contiene todos los datos que los expertos necesitan:
    """)

    try:
        # AsegÃºrate de que 'informe_modelo.pdf' estÃ© en la ruta './reports/'
        with open("./reports/informe_modelo.pdf", "rb") as file:
            st.download_button(
                label="Descargar Informe Completo (PDF)",
                data=file,
                file_name="informe_moderador_ia.pdf",
                mime="application/pdf",
                key="download_report_pdf"
            )
    except FileNotFoundError:
        st.warning("El archivo del informe (`informe_modelo.pdf`) no se encontrÃ³ en la ruta `./reports/`. Por favor, verifica que la carpeta `reports` y el archivo existan.")
    except Exception as e:
        st.error(f"Error al preparar el archivo para descarga: {e}")


with tab_conclusions:
    st.title("ğŸ”® Conclusiones y PrÃ³ximos Pasos: El Futuro de la ModeraciÃ³n")
    st.markdown("---")

    # ConclusiÃ³n general
    st.header("ğŸŒ Explorando el Horizonte de la ModeraciÃ³n Inteligente")
    st.write("""
    Este moderador de chat basado en inteligencia artificial representa un componente clave dentro de una estrategia moderna de gestiÃ³n de comunidades digitales. Aunque su versiÃ³n actual ya es funcional, el potencial de evoluciÃ³n es amplio y prometedor.
    """)

    # Integraciones e innovaciÃ³n futura
    st.subheader("ğŸš€ Futuras lÃ­neas de desarrollo")
    st.markdown("""
    - **ğŸ”— IntegraciÃ³n mediante APIs:** El modelo puede desplegarse como un **microservicio** conectado a travÃ©s de una **API REST** (por ejemplo, con Flask o FastAPI), permitiendo una moderaciÃ³n en tiempo real directamente en plataformas de chat.

    - **ğŸ§  IA Conversacional para intervenciÃ³n directa:** Una IA capaz no solo de detectar, sino tambiÃ©n de **intervenir de forma educativa**. Por ejemplo:
        - *"Lo que has dicho es ofensivo. Por favor, modera tu lenguaje."*
        - O incluso una **reescritura inteligente** del mensaje. Por ejemplo:
            > Usuario escribe: "*me cago en tu ... no sabes jugar tendrÃ­as que hacer esto manco*"  
            > La IA reescribe: "*PodrÃ­as intentar esto en su lugar. Me estoy frustrando con el juego.*"  
            Esto transforma un mensaje tÃ³xico en uno constructivo, sin cortar la comunicaciÃ³n.

    - **ğŸ§© ModeraciÃ³n contextual:** Evolucionar el sistema para que no evalÃºe solo mensajes individuales, sino **el contexto completo de la conversaciÃ³n**, permitiendo distinguir mejor entre toxicidad real y humor, sarcasmo o lenguaje habitual dentro de un juego o comunidad.
    """)

    # PrÃ³ximos pasos concretos
    st.subheader("ğŸ“ˆ PrÃ³ximos pasos")
    st.markdown("""
    - **ğŸ“Š Ampliar el dataset:** Incluir mÃ¡s ejemplos variados de toxicidad permitirÃ¡ mejorar la precisiÃ³n del modelo y adaptarse a diferentes formas de comunicaciÃ³n.
    - **ğŸŒ MultilingÃ¼ismo:** Adaptar el modelo para detectar toxicidad en **otros idiomas**, no solo en inglÃ©s, ampliando su utilidad a nivel global.
    - **ğŸ§ª Pruebas en entornos reales:** Aplicar el sistema con **supervisiÃ³n humana** en plataformas reales para identificar errores, ajustar el modelo y alimentarlo con nuevos casos.
    - **ğŸ§° APIs modulares:** Desarrollar APIs **robustas y plug-and-play** que faciliten su integraciÃ³n por parte de terceros (empresas, desarrolladores, plataformas).

    """)

    # ReflexiÃ³n final
    st.subheader("ğŸ’¡ ReflexiÃ³n final")
    st.markdown("""
    La **inteligencia artificial** puede y debe ser una **aliada clave** en la construcciÃ³n de comunidades digitales **mÃ¡s seguras, inclusivas y saludables**.

    Este sistema **no busca reemplazar a los moderadores humanos**, sino **asistirlos y potenciar su labor**. Con mÃ¡s datos, validaciÃ³n continua y desarrollo responsable, podemos acercarnos cada vez mÃ¡s a una **moderaciÃ³n automÃ¡tica efectiva y Ã©tica**.
    """)
