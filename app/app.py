
import streamlit as st
import pandas as pd
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import classification_report
import json
import time
import random

# --- Configuraci√≥n inicial de la p√°gina de Streamlit ---
# Esta debe ser la PRIMERA llamada a st. en todo el script, despu√©s de los imports.
st.set_page_config(
    page_title="Moderador de Chat IA",
    layout="centered",
    page_icon="ü§ñ",
    initial_sidebar_state="collapsed" 
)

# --- 0. Configuraci√≥n inicial y carga del modelo/tokenizador ---
FINETUNED_MODEL_PATH = './models/modelo_toxicidad_guardado'
BASE_MODEL_NAME_FOR_TOKENIZER = 'distilbert-base-uncased'

num_classes = 4
id_to_label = {
    0: 'Acci√≥n/Juego',
    1: 'Gravemente T√≥xico',
    2: 'Levemente T√≥xico',
    3: 'No T√≥xico'
}

label_to_id = {v: k for k, v in id_to_label.items()}

@st.cache_resource
def load_resources_cached(model_path_cached, base_model_name_for_tokenizer_cached, num_labels_cached):
    """
    Carga el tokenizador y el modelo finetuneado, y lo mueve al dispositivo adecuado.
    Esta funci√≥n se cachea con st.cache_resource para una carga √∫nica.
    """
    try:
        tokenizer = AutoTokenizer.from_pretrained(base_model_name_for_tokenizer_cached)
        model = AutoModelForSequenceClassification.from_pretrained(model_path_cached, num_labels=num_labels_cached)
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model.to(device)
        model.eval()

        
        return tokenizer, model, device

    except Exception as e:
        st.error(f"¬°Ups! Error al cargar el modelo o tokenizador desde '{model_path_cached}': {e}")
        st.info("Aseg√∫rate de que el modelo est√© entrenado y guardado correctamente en esa ruta.")
        st.info("Si est√°s ejecutando la app por primera vez o has movido archivos, verifica la ruta y los permisos.")
        return None, None, None

# Llama a la funci√≥n cacheada para cargar los recursos
tokenizer, model, device = load_resources_cached(FINETUNED_MODEL_PATH, BASE_MODEL_NAME_FOR_TOKENIZER, num_classes)

if model is None or tokenizer is None:
    st.stop() # Detiene la ejecuci√≥n de la app si el modelo no se pudo cargar

# --- Inicializaci√≥n de variables de estado de Streamlit ---
# Todas las variables de sesi√≥n deben inicializarse para evitar errores.
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'grave_count' not in st.session_state:
    st.session_state.grave_count = 0
if 'leve_count' not in st.session_state:
    st.session_state.leve_count = 0
if 'is_banned' not in st.session_state:
    st.session_state.is_banned = False
if 'chat_input' not in st.session_state: # Para el widget de texto del chat
    st.session_state.chat_input = ""

# Umbrales configurables por la empresa para la Demostraci√≥n Interactiva
if 'max_graves' not in st.session_state:
    st.session_state.max_graves = 3 # Valor por defecto
if 'max_leves' not in st.session_state:
    st.session_state.max_leves = 5 # Valor por defecto
if 'ban_threshold_graves' not in st.session_state:
    st.session_state.ban_threshold_graves = 10 # Umbral de baneo por graves
if 'ban_threshold_total_toxic' not in st.session_state:
    st.session_state.ban_threshold_total_toxic = 15 # Umbral de baneo por toxicidad total

# --- Funciones Auxiliares ---
def get_prediction(text, tokenizer, model, device, id_to_label):
    if model is None or tokenizer is None:
        return "Modelo no cargado", None, None

    inputs = tokenizer(
        text,
        truncation=True,
        padding='max_length',
        max_length=256,
        return_tensors='pt'
    ).to(device)

    with torch.no_grad():
        outputs = model(**inputs)

    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].cpu().numpy()
    predicted_id = np.argmax(probabilities).item()
    predicted_label = id_to_label[predicted_id]

    return predicted_label, probabilities, predicted_id

# Funci√≥n para resetear la demo (usada en la Demostraci√≥n Interactiva)
def reset_demo():
    st.session_state.grave_count = 0
    st.session_state.leve_count = 0
    # Aseguramos que tambi√©n se resetean los contadores de aliados/enemigos
    st.session_state.grave_count_ally = 0
    st.session_state.leve_count_ally = 0
    st.session_state.grave_count_enemy = 0
    st.session_state.leve_count_enemy = 0
    st.session_state.is_banned = False
    st.session_state.chat_history = []
    st.session_state.chat_input = "" 

# Funci√≥n para crear burbujas de mensaje HTML
def create_bubble(message, sender="t√∫", msg_type="normal"):
    colors = {
        "grave": "#ffcccc", # Rojo claro
        "leve": "#ffe0b2",  # Naranja claro
        "no_toxic": "#e0f7fa", # Azul muy claro
        "action": "#e8f5e9", # Verde claro
        "system": "#eeeeee", # Gris muy claro
        "enemy": "#f3e5f5",  # Morado claro
        "ally": "#dcedc8",   # Verde pistacho claro
        "warning": "#fff3cd", # Amarillo claro
        "ban": "#f8d7da",    # Rojo muy claro, m√°s pastel
    }
    style = f"background-color:{colors.get(msg_type, '#f0f0f0')};border-radius:10px;padding:10px;margin:6px 0"
    return f"""
    <div style='{style}'>
        <strong>{sender}:</strong> {message}
    </div>
    """

def logo():
    return """
    <div style='
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        text-align: center;
        padding: 20px 0;
        user-select: none;
    '>
        <h1 style='
            font-size: 56px;
            font-weight: 900;
            color: #4a90e2;
            margin: 0;
            letter-spacing: 3px;
            text-shadow: 1px 1px 3px rgba(0,0,0,0.1);
        '>
            <span style='color:#262730;'>Moderador</span> <span style='color:#4a90e2;'>Inteligente</span> <span style='color:#262730;'>de Chat</span>
        </h1>
        <p style='
            margin-top: 6px;
            font-size: 18px;
            color: #666666;
            font-weight: 500;
            letter-spacing: 1px;
        '>
            Tu Aliado en la Moderaci√≥n Online
        </p>
    </div>
    """

# --- NAVEGACI√ìN CON PESTA√ëAS (TABS) ---
tab_intro, tab_demo, tab_csv, tab_performance, tab_conclusions = st.tabs([
    "1. Introducci√≥n",
    "2. Demostraci√≥n Interactiva",
    "3. Herramienta de An√°lisis",
    "4. Rendimiento ",
    "5. Pr√≥ximos Pasos"
])

# --- Contenido de las P√°ginas ---

with tab_intro:
    st.markdown(logo(), unsafe_allow_html=True)

    # Imagen decorativa (moderna y sin warnings)
    st.image(
        "https://images.unsplash.com/photo-1519389950473-47ba0277781c?auto=format&fit=crop&w=800&q=80",
        caption="Moderaci√≥n con IA en comunidades digitales",
        use_container_width=True
    )

    st.markdown("---")

    # Secci√≥n: ¬øPor qu√© un Moderador de Chat con IA?
    with st.container():
        st.header("üéØ ¬øPor qu√© un Moderador de Chat con IA?")

        st.subheader("üö® Un problema creciente")
        st.markdown("""
        La toxicidad en los entornos online, especialmente en videojuegos multijugador, se ha convertido en un problema creciente que afecta tanto a los usuarios como a las plataformas que los albergan.
        """)

        st.subheader("üìä Datos alarmantes")
        st.markdown("""
        - M√°s del **80%** de los jugadores han experimentado alg√∫n tipo de acoso en juegos en l√≠nea.  
        - Un **68%** ha recibido amenazas f√≠sicas, acecho o acoso sostenido.  
        - El **53%** ha sido v√≠ctima de ataques basados en **raza**, **g√©nero**, **orientaci√≥n sexual** u otros aspectos personales.
        """)

        st.subheader("üß† Consecuencias reales")
        st.markdown("""
        Este tipo de comportamiento no solo **deteriora la experiencia del usuario**, sino que tambi√©n genera consecuencias serias a nivel social:

        - **Aislamiento**  
        - **Ansiedad**  
        - **Pensamientos depresivos**
        """)

        st.subheader("ü§ñ Una soluci√≥n inteligente")
        st.markdown("""
        Un **Moderador de Chat Inteligente** basado en IA no solo detecta y filtra mensajes t√≥xicos, sino que tambi√©n:

        - **Protege** a las comunidades digitales.  
        - **Garantiza** un entorno seguro y saludable para todos.
        """)

    st.markdown("---")

    # Secci√≥n: ¬øPor qu√© esto importa a las empresas?
    with st.container():
        st.header("üè¢ ¬øPor qu√© esto importa a las empresas?")

        st.subheader("üí¨ La toxicidad va m√°s all√° de los videojuegos")
        st.markdown("""
        Plataformas con interacci√≥n constante ‚Äî como **foros**, **redes sociales**, **e-commerce** o **servicios de atenci√≥n al cliente** ‚Äî tambi√©n enfrentan este reto.
        """)

        st.subheader("üíº Ventajas comerciales de usar IA")
        st.markdown("""
        - ‚úÖ **Mejora la experiencia del usuario**: Los entornos saludables incrementan la satisfacci√≥n, retenci√≥n y *engagement*.  
        - üõ°Ô∏è **Protecci√≥n de la marca**: Evita que contenidos da√±inos afecten la reputaci√≥n empresarial.  
        - ‚ö° **Escalabilidad y eficiencia**: Modera grandes vol√∫menes en tiempo real, sin fatiga ni sesgos.  
        - üí∏ **Reducci√≥n de costos**: Disminuye la necesidad de equipos humanos para tareas repetitivas.  
        - üîç **An√°lisis y prevenci√≥n**: Detecta patrones t√≥xicos para anticiparse a futuros problemas.
        """)

    st.markdown("---")

    # Secci√≥n: Fuentes y estudios relevantes
    with st.container():
        st.subheader("üìö Fuentes y estudios relevantes")
        with st.expander("üîé Consulta las investigaciones que respaldan estos datos"):
            st.markdown("""
            - üìà *El Tel√©grafo (2024)* reporta que el acoso en juegos online aument√≥ un **74%** en el √∫ltimo a√±o. M√°s del **80%** de jugadores han sufrido acoso, y el **68%** recibi√≥ amenazas f√≠sicas, acecho o acoso sostenido.  
              [Ver art√≠culo](https://www.eltelegrafo.com.ec/noticias/sociedad/6/acoso-juegos-online-aumento-ultimo-ano)

            - üìä *Pew Research Center (2021)* se√±ala que el **41%** de los adultos en EE.UU. ha sido acosado online, un problema transversal en m√∫ltiples plataformas.  
              [Ver estudio](https://www.pewresearch.org/internet/2021/01/13/the-state-of-online-harassment/)
            """)

with tab_demo:

    with st.sidebar:
        st.header("‚öôÔ∏è Ajustes de umbrales")

        # Aseg√∫rate de que los sliders usan las variables de st.session_state para sus valores
        st.session_state.max_graves = st.slider(
            "üî¥ Umbral de advertencia grave", 1, 10,
            value=st.session_state.max_graves, key="slider_max_graves" # A√±adido key
        )
        st.session_state.max_leves = st.slider(
            "üü† Umbral de advertencia leve", 1, 10,
            value=st.session_state.max_leves, key="slider_max_leves" # A√±adido key
        )
        st.session_state.ban_threshold_graves = st.slider(
            "üö´ Umbral para ban por graves", 1, 10,
            value=st.session_state.ban_threshold_graves, key="slider_ban_graves" # A√±adido key
        )
        st.session_state.ban_threshold_total_toxic = st.slider(
            "üö´ Umbral para ban por total t√≥xicos", 1, 20,
            value=st.session_state.ban_threshold_total_toxic, key="slider_ban_total" # A√±adido key
        )

        if st.button("Reiniciar Demo", key="reset_demo_button_sidebar"):
            reset_demo()
           

    st.title("ü§ñ Demo Interactivo: Moderador de Chat")
    st.markdown("---")

    st.header("ü§î ¬øC√≥mo funciona esta demo?")
    st.markdown(f"""
    Esta es una **simulaci√≥n de chat moderado por IA**. Puedes enviar mensajes y ver c√≥mo el sistema los clasifica y act√∫a en consecuencia.

    1. ‚úèÔ∏è **Escribe un mensaje** en la caja de texto inferior.
    2. üì§ Haz clic en **"Enviar mensaje"** o presiona `Enter`.
    3. ü§ñ El mensaje ser√° clasificado por el modelo en una de las **{num_classes} categor√≠as**: {', '.join(id_to_label.values())}.
    4. ‚ö†Ô∏è Si el mensaje se detecta como **t√≥xico**, aparecer√° una advertencia y se contar√° en los indicadores superiores.
    5. üö´ Si superas ciertos **umbrales de toxicidad** (configurables en la barra lateral), ser√°s **bloqueado** del chat.
    6. üìä En los contadores superiores se muestra tanto tu comportamiento como el de los personajes simulados (aliado y enemigo).
    7. üîÑ Usa el bot√≥n **"Reiniciar Demo"** para empezar de nuevo cuando lo necesites.
    """)

    st.info("""
    üó®Ô∏è Para simular una conversaci√≥n real, el sistema genera autom√°ticamente **mensajes aleatorios** de un **aliado** y un **enemigo** tras cada mensaje tuyo.  
    ‚ùó **Importante**: estos mensajes **no responden directamente a tus mensajes**, son generados aleatoriamente. Este sistema no es un bot de conversaci√≥n, sino una inteligencia artificial que clasifica mensajes de chat seg√∫n su tono.
    """)


    st.markdown("---")

    st.subheader("Simulador de chat")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Tus mensajes t√≥xicos graves", st.session_state.grave_count)
        st.metric("Tus mensajes t√≥xicos leves", st.session_state.leve_count)
    with col2:
        # Asegurarse de que estas variables est√©n inicializadas en reset_demo o al inicio del script
        if 'grave_count_ally' not in st.session_state: st.session_state.grave_count_ally = 0
        if 'leve_count_ally' not in st.session_state: st.session_state.leve_count_ally = 0
        st.metric("Aliado - t√≥xicos graves", st.session_state.grave_count_ally)
        st.metric("Aliado - t√≥xicos leves", st.session_state.leve_count_ally)
    with col3:
        # Asegurarse de que estas variables est√©n inicializadas en reset_demo o al inicio del script
        if 'grave_count_enemy' not in st.session_state: st.session_state.grave_count_enemy = 0
        if 'leve_count_enemy' not in st.session_state: st.session_state.leve_count_enemy = 0
        st.metric("Enemigo - t√≥xicos graves", st.session_state.grave_count_enemy)
        st.metric("Enemigo - t√≥xicos leves", st.session_state.leve_count_enemy)

    # --- L√≥gica de baneo y chat ---
    # La visualizaci√≥n del historial de chat se mueve aqu√≠, antes del input,
    # para que siempre sea visible, incluso si el usuario est√° baneado.
    st.markdown("### Historial del Chat:")
    # Mostrar el chat hist√≥rico (en orden cronol√≥gico si se prefiere)
    # Si quieres el m√°s nuevo arriba, usa reversed(st.session_state.chat_history)
    for bubble in st.session_state.chat_history:
        st.markdown(bubble, unsafe_allow_html=True)

    if st.session_state.is_banned:
        st.markdown(create_bubble("üö´ ¬°HAS SIDO BLOQUEADO DEL CHAT! üö´ Excediste los l√≠mites de toxicidad.", "üõë Sistema", "ban"), unsafe_allow_html=True)
        if st.button("Desbloquear (Reiniciar Demo)", key="unban_button"):
            reset_demo()
            # st.experimental_rerun() # No es necesario aqu√≠

    else:
        # --- Funci√≥n Callback para el env√≠o de mensaje ---
        def send_message_and_update_demo():
            user_message = st.session_state.chat_input # Accede al valor del input con su key

            if not user_message: # Si el mensaje est√° vac√≠o
                st.warning("Por favor, escribe un mensaje.")
                return # Salir de la funci√≥n si no hay mensaje

            # Realizar predicci√≥n: ¬°Aqu√≠ es donde se usa el modelo!
            predicted_label, probabilities, predicted_id = get_prediction(user_message, tokenizer, model, device, id_to_label)

            # --- A√±adir mensaje del usuario al historial ---
            if predicted_label == id_to_label[1]:  # Gravemente T√≥xico
                st.session_state.grave_count += 1
                bubble = create_bubble(user_message + f"<br><em>Clasificado como: <b>{predicted_label}</b></em>", "üßë T√∫", "grave")
                st.session_state.chat_history.append(bubble)
                if st.session_state.grave_count >= st.session_state.max_graves:
                    warning = create_bubble("üö® ADVERTENCIA: Demasiados mensajes t√≥xicos graves.", "‚ö†Ô∏è Sistema", "warning")
                    st.session_state.chat_history.append(warning)
                if st.session_state.grave_count >= st.session_state.ban_threshold_graves:
                    st.session_state.is_banned = True
                    ban_msg = create_bubble("üö´ Has sido bloqueado por toxicidad grave.", "üõë Sistema", "ban")
                    st.session_state.chat_history.append(ban_msg)

            elif predicted_label == id_to_label[2]:  # Levemente T√≥xico
                st.session_state.leve_count += 1
                bubble = create_bubble(user_message + f"<br><em>Clasificado como: <b>{predicted_label}</b></em>", "üßë T√∫", "leve")
                st.session_state.chat_history.append(bubble)
                if st.session_state.leve_count >= st.session_state.max_leves:
                    warning = create_bubble("‚ö†Ô∏è AVISO: Varios mensajes t√≥xicos leves.", "‚ö†Ô∏è Sistema", "warning")
                    st.session_state.chat_history.append(warning)
                if (st.session_state.grave_count + st.session_state.leve_count) >= st.session_state.ban_threshold_total_toxic:
                    st.session_state.is_banned = True
                    ban_msg = create_bubble("üö´ Has sido bloqueado por toxicidad acumulada.", "üõë Sistema", "ban")
                    st.session_state.chat_history.append(ban_msg)

            elif predicted_label == id_to_label[3]:  # No T√≥xico
                bubble = create_bubble(user_message + f"<br><em>Clasificado como: <b>{predicted_label}</b></em>", "üßë T√∫", "no_toxic")
                st.session_state.chat_history.append(bubble)

            else: # Acci√≥n/Juego
                bubble = create_bubble(user_message + f"<br><em>Clasificado como: <b>{predicted_label}</b></em>", "üßë T√∫", "action")
                st.session_state.chat_history.append(bubble)

            # --- Mensajes aleatorios de Aliado/Enemigo ---
            def ally_message_generator(): # Renombrado para evitar conflicto con la funci√≥n ally_message() anterior
                options = [
                    # No toxic
                    ("wp", "no_toxic"),
                    ("Gj, team!", "no_toxic"),
                    ("You're doing great!", "no_toxic"),
                    ("gg", "no_toxic"),
    
                    # Action/gameplay
                    ("Push mid!", "action"),
                    ("Group up!", "action"),
                    ("Defend the tower!", "action"),
                    ("Fall back!", "action"),
    
                    # Mild toxicity
                    ("Why are you feeding?", "leve"),
                    ("Do something, please.", "leve"),
                    ("You're making it harder for everyone.", "leve"),
                    ("Wake up, this is ranked!", "leve"),

                    # Severe toxicity
                    ("You're completely useless.", "grave"),
                    ("Uninstall the game.", "grave"),
                    ("STUPID", "grave"),
                    ("We're losing because you DUMB.", "grave")
]
                text, msg_type = random.choice(options)
                if msg_type == "grave":
                    st.session_state.grave_count_ally += 1
                elif msg_type == "leve":
                    st.session_state.leve_count_ally += 1
                return create_bubble(text, "üü¢ Aliado", "ally") # Usar "ally" para el tipo de burbuja

            def enemy_message_generator(): # Renombrado
                options = [
                    # No toxic
                    ("You're not bad... for a beginner.", "no_toxic"),
                    ("GG so far.", "no_toxic"),
                    ("You're lucky this time.", "no_toxic"),
                    ("gl hf", "no_toxic"),

                    # Action/gameplay
                    ("I'm pushing top.", "action"),
                    ("Don't let them take it!", "action"),
                    ("We need to end this now.", "action"),
                    ("Farm and group mid.", "action"),

                    # Mild toxicity
                    ("surrender already, boring game", "leve"),
                    ("EZ, learn how to play", "leve"),
                    ("You play like a bot.", "leve"),
                    ("You're the reason your team is losing.", "leve"),

                    # Severe toxicity
                    ("You're absolute garbage.", "grave"),
                    ("Go cry, bitch.", "grave"),
                    ("Did you forget how to play? are you a girl? ", "grave"),
                    ("You're the worst player I've seen, and thats sad", "grave")
]
                text, msg_type = random.choice(options)
                if msg_type == "grave":
                    st.session_state.grave_count_enemy += 1
                elif msg_type == "leve":
                    st.session_state.leve_count_enemy += 1
                return create_bubble(text, "üî¥ Enemigo", "enemy") # Usar "enemy" para el tipo de burbuja

            # A√±adir mensajes de IA al historial
            st.session_state.chat_history.append(ally_message_generator())
            st.session_state.chat_history.append(enemy_message_generator())

            # Vaciar el input de texto despu√©s de todo el procesamiento
            st.session_state.chat_input = ""
            # No necesitas st.experimental_rerun() aqu√≠, on_click maneja el refresco.


        # El campo de entrada de texto
        # Ya no usamos on_change para limpiar, se limpia dentro del callback
        st.text_input("Escribe tu mensaje aqu√≠:", key="chat_input")

        # El bot√≥n que activa la funci√≥n callback para enviar y procesar el mensaje
        st.button("Enviar mensaje", on_click=send_message_and_update_demo, key="send_message_button_demo")

    # Mover la visualizaci√≥n del historial de chat arriba para que siempre sea visible
    # st.markdown("### Historial del Chat:") # Ya lo puse arriba

with tab_csv:
    st.title("üõ†Ô∏è Herramienta de An√°lisis de Toxicidad por Lotes")
    st.markdown("---")

    st.header("Carga tu CSV de Comentarios")
    st.write("""
    Esta herramienta te permite subir un archivo CSV con una columna de comentarios
    y el modelo de IA a√±adir√° una nueva columna clasificando cada comentario
    en 'Gravemente T√≥xico', 'Levemente T√≥xico', 'No T√≥xico' o 'Acci√≥n/Juego'.
    """)

    uploaded_file = st.file_uploader("Sube tu archivo CSV aqu√≠", type="csv")

    if uploaded_file is not None:
        try:
            df_upload = pd.read_csv(uploaded_file)
            st.success("Archivo CSV cargado exitosamente.")
            st.dataframe(df_upload.head())

            # Permite al usuario seleccionar la columna si no es obvio
            column_to_analyze = st.selectbox(
                "Selecciona la columna que contiene los comentarios:",
                df_upload.columns,
                key="csv_column_selector" # A√±adido key
            )

            if st.button("Analizar Comentarios", key="analyze_csv_button"): # A√±adido key
                if model is not None and tokenizer is not None:
                    with st.spinner("Analizando comentarios... Esto puede tardar unos minutos para archivos grandes."):
                        predictions = []
                        # Asegurarse de que los comentarios son strings y manejar NaN/vac√≠os
                        for comment in df_upload[column_to_analyze].astype(str).fillna(''):
                            predicted_label, _, _ = get_prediction(comment, tokenizer, model, device, id_to_label)
                            predictions.append(predicted_label)

                        df_upload['clasificacion_toxicidad'] = predictions
                        st.subheader("Resultados del An√°lisis:")
                        st.dataframe(df_upload)

                        # Opci√≥n de descarga
                        csv_output = df_upload.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="Descargar CSV con Clasificaciones",
                            data=csv_output,
                            file_name="comentarios_clasificados.csv",
                            mime="text/csv",
                            key="download_classified_csv" # A√±adido key
                        )
                else:
                    st.error("El modelo no est√° cargado. No se puede realizar el an√°lisis.")
        except Exception as e:
            st.error(f"Error al leer o procesar el archivo CSV: {e}")
            st.info("Aseg√∫rate de que el archivo es un CSV v√°lido y que no contiene caracteres problem√°ticos.")


with tab_performance:
    st.title("üìà Rendimiento del Modelo: Fiabilidad y Capacidades")
    st.markdown("---")

    st.header("¬øHasta qu√© punto es fiable nuestro moderador IA?")
    st.write("""
    Nuestro modelo de Inteligencia Artificial es el coraz√≥n de este sistema de moderaci√≥n. Ha sido entrenado
    con mucho cuidado y probado a fondo para asegurar que es **eficaz y fiable**. Aqu√≠ te explicamos, de
    forma sencilla, qu√© tan bien funciona y d√≥nde brilla m√°s.
    """)

    # --- DATOS DE RENDIMIENTO HARDCODEADOS DIRECTAMENTE EN EL C√ìDIGO ---
    # Estos son los datos que antes se cargaban del JSON. Ahora est√°n aqu√≠.
    hardcoded_report_data = {
        "Acci√≥n/Juego": {"precision": 0.739, "recall": 0.845, "f1-score": 0.788, "support": "N/A"}, # 'support' es el n√∫mero de ejemplos
        "Gravemente T√≥xico": {"precision": 0.872, "recall": 0.886, "f1-score": 0.879, "support": "N/A"},
        "Levemente T√≥xico": {"precision": 0.793, "recall": 0.718, "f1-score": 0.753, "support": "N/A"},
        "No T√≥xico": {"precision": 0.954, "recall": 0.954, "f1-score": 0.954, "support": "N/A"},
        "accuracy": 0.9174,
        "macro avg": {"precision": 0.8395, "recall": 0.85075, "f1-score": 0.8435, "support": "N/A"},
        "weighted avg": {"precision": 0.9175, "recall": 0.9174, "f1-score": 0.9175, "support": "N/A"}
    }

    # Creamos el DataFrame directamente desde los datos hardcodeados
    report_df = pd.DataFrame(hardcoded_report_data).transpose()

    # Redondeamos las columnas num√©ricas para una mejor visualizaci√≥n
    # y manejamos el caso de 'accuracy' que no es un diccionario
    for col in ['precision', 'recall', 'f1-score']:
        if col in report_df.columns:
            report_df[col] = pd.to_numeric(report_df[col], errors='coerce').round(3)
    if 'accuracy' in report_df.index:
        report_df.loc['accuracy'] = pd.to_numeric(report_df.loc['accuracy'], errors='coerce').round(4) # Accuracy puede tener m√°s decimales


    st.subheader("M√©tricas de Evaluaci√≥n Detalladas:")
    st.dataframe(report_df)

    st.markdown("""
    ### **¬øC√≥mo se comporta el modelo? Un resumen para todos:**

    Imagina que el modelo es como un **experto revisor de chat**. Analiza los mensajes y decide
    si son t√≥xicos o no. Basado en nuestras pruebas, aqu√≠ te contamos lo que hace genial y d√≥nde puede mejorar:

    ---

    #### **‚úÖ Lo que el modelo hace EXCEPCIONALMENTE bien (Puntos Fuertes):**

    * **Detecta la toxicidad m√°s grave (¬°Y muy bien!):** Cuando un mensaje es **"Gravemente T√≥xico"**, nuestro modelo es **muy, muy bueno** identific√°ndolo. Tiene una fiabilidad de casi el **88%** en esta tarea. Esto es crucial porque significa que los mensajes m√°s da√±inos y problem√°ticos son r√°pidamente detectados y gestionados. Protege a tu comunidad de lo peor.

    * **Reconoce lo que NO es t√≥xico (¬°Casi perfecto!):** El modelo es **excelente** a la hora de decir cu√°ndo un mensaje es **"No T√≥xico"**. Con una fiabilidad del **95.4%**, casi nunca se equivoca al dejar pasar conversaciones normales y saludables. Esto es vital para no molestar a los usuarios que se comunican bien.

    * **Precisi√≥n general impresionante:** En total, el modelo acierta en casi **9 de cada 10 mensajes** (un **91.74%** de precisi√≥n general). Esto nos dice que, en la mayor√≠a de los casos, puedes confiar en su criterio para mantener el chat limpio.

    ---

    #### **‚ö†Ô∏è D√≥nde el modelo puede ser m√°s "cauteloso" (√Åreas de Oportunidad):**

    * **Toxicidad leve (el matiz es complicado):** Identificar la toxicidad **"Levemente T√≥xica"** es el reto m√°s grande. Piensa en el sarcasmo, las indirectas o los comentarios un poco molestos pero no tan agresivos. Aqu√≠ el modelo es **razonablemente bueno** (alrededor del **75.3%**), pero a veces puede **dejar pasar** algunos mensajes sutiles. Esto es normal en la IA, ya que la l√≠nea entre un comentario "regular" y uno "ligeramente t√≥xico" puede ser muy fina y subjetiva para una m√°quina.

    * **Mensajes de "Acci√≥n/Juego":** Aunque clasifica bien la mayor√≠a, en los mensajes de **"Acci√≥n/Juego"** (como "¬°Vamos a por el objetivo!"), su precisi√≥n es un poco m√°s baja (alrededor del **78.8%**). A veces, puede confundir estos mensajes con otros "No T√≥xicos". Esto se debe a que el lenguaje del juego puede ser muy similar al de las conversaciones normales.

    ---

    #### **En resumen:**

    Este moderador es una **herramienta poderosa y muy fiable** para detectar los mensajes m√°s peligrosos y para asegurar que el chat normal fluye sin problemas. Para las toxicidades m√°s sutiles o las categor√≠as de contenido espec√≠ficas, es una base excelente que puede mejorarse con el tiempo y el uso.

    ---
    """)

    # --- La secci√≥n de descarga del PDF se mantiene igual ---
    st.markdown("---")
    st.header("¬øQuieres ver los n√∫meros exactos en detalle?")
    st.write("""
    Para aquellos interesados en los detalles t√©cnicos, las m√©tricas completas y un an√°lisis exhaustivo
    del rendimiento de nuestro modelo, puedes descargar el informe completo de evaluaci√≥n aqu√≠.
    Contiene todos los datos que los expertos necesitan:
    """)

    try:
        # Aseg√∫rate de que 'informe_modelo.pdf' est√© en la ruta './reports/'
        with open("./reports/informe_modelo.pdf", "rb") as file:
            st.download_button(
                label="Descargar Informe Completo (PDF)",
                data=file,
                file_name="informe_moderador_ia.pdf",
                mime="application/pdf",
                key="download_report_pdf"
            )
    except FileNotFoundError:
        st.warning("El archivo del informe (`informe_modelo.pdf`) no se encontr√≥ en la ruta `./reports/`. Por favor, verifica que la carpeta `reports` y el archivo existan.")
    except Exception as e:
        st.error(f"Error al preparar el archivo para descarga: {e}")


with tab_conclusions:
    st.title("üîÆ Conclusiones y Pr√≥ximos Pasos: El Futuro de la Moderaci√≥n")
    st.markdown("---")

    # Conclusi√≥n general
    st.header("üåê Explorando el Horizonte de la Moderaci√≥n Inteligente")
    st.write("""
    Este moderador de chat basado en inteligencia artificial representa un componente clave dentro de una estrategia moderna de gesti√≥n de comunidades digitales. Aunque su versi√≥n actual ya es funcional, el potencial de evoluci√≥n es amplio y prometedor.
    """)

    # Integraciones e innovaci√≥n futura
    st.subheader("üöÄ Futuras l√≠neas de desarrollo")
    st.markdown("""
    - **üîó Integraci√≥n mediante APIs:** El modelo puede desplegarse como un **microservicio** conectado a trav√©s de una **API REST** (por ejemplo, con Flask o FastAPI), permitiendo una moderaci√≥n en tiempo real directamente en plataformas de chat.

    - **üß† IA Conversacional para intervenci√≥n directa:** Una IA capaz no solo de detectar, sino tambi√©n de **intervenir de forma educativa**. Por ejemplo:
        - *"Lo que has dicho es ofensivo. Por favor, modera tu lenguaje."*
        - O incluso una **reescritura inteligente** del mensaje. Por ejemplo:
            > Usuario escribe: "*me cago en tu ... no sabes jugar tendr√≠as que hacer esto manco*"  
            > La IA reescribe: "*Podr√≠as intentar esto en su lugar. Me estoy frustrando con el juego.*"  
            Esto transforma un mensaje t√≥xico en uno constructivo, sin cortar la comunicaci√≥n.

    - **üß© Moderaci√≥n contextual:** Evolucionar el sistema para que no eval√∫e solo mensajes individuales, sino **el contexto completo de la conversaci√≥n**, permitiendo distinguir mejor entre toxicidad real y humor, sarcasmo o lenguaje habitual dentro de un juego o comunidad.
    """)

    # Pr√≥ximos pasos concretos
    st.subheader("üìà Pr√≥ximos pasos")
    st.markdown("""
    - **üìä Ampliar el dataset:** Incluir m√°s ejemplos variados de toxicidad permitir√° mejorar la precisi√≥n del modelo y adaptarse a diferentes formas de comunicaci√≥n.
    - **üåç Multiling√ºismo:** Adaptar el modelo para detectar toxicidad en **otros idiomas**, no solo en ingl√©s, ampliando su utilidad a nivel global.
    - **üß™ Pruebas en entornos reales:** Aplicar el sistema con **supervisi√≥n humana** en plataformas reales para identificar errores, ajustar el modelo y alimentarlo con nuevos casos.
    - **üß∞ APIs modulares:** Desarrollar APIs **robustas y plug-and-play** que faciliten su integraci√≥n por parte de terceros (empresas, desarrolladores, plataformas).

    """)

    # Reflexi√≥n final
    st.subheader("üí° Reflexi√≥n final")
    st.markdown("""
    La **inteligencia artificial** puede y debe ser una **aliada clave** en la construcci√≥n de comunidades digitales **m√°s seguras, inclusivas y saludables**.

    Este sistema **no busca reemplazar a los moderadores humanos**, sino **asistirlos y potenciar su labor**. Con m√°s datos, validaci√≥n continua y desarrollo responsable, podemos acercarnos cada vez m√°s a una **moderaci√≥n autom√°tica efectiva y √©tica**.
    """)
